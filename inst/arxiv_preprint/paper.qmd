---
title: "Welding R and C++: A Tale of Two Programming Languages"
date: 2024-09-06
author1: "Mauricio Vargas Sep√∫lveda (ORCID 0000-0003-1017-7574)"
email1: m.sepulveda@mail.utoronto.ca
affiliation11: Department of Political Science, University of Toronto
affiliation12: Munk School of Global Affairs and Public Policy, University of Toronto
format:
  pdf:
    pdf-engine: pdflatex
    template: "template.tex"
    keep-tex: true
    post-process: "move_pdf.sh"
bibliography: references.bib
csl: chicago.csl
fontsize: 12pt
linespacing: 1.5
margin: 1
paper: letterpaper
customfonts: false
sansserif: false
amsthm: false
outline: true
---

# Abstract

This article compares `cpp11armadillo` and `cpp11eigen`, new R packages that
integrate the powerful Armadillo and Eigen C++ libraries for linear algebra into
the R programming environment. This article provides a detailed comparison
between Armadillo and Eigen speed and syntax. The goal of these packages is to
simplify a part of the process of solving bottlenecks by using C++ within R,
these offer additional ease of integration for users who require
high-performance linear algebra operations in their R workflows. This document
aims to discuss the tradeoff between computational efficiency and accessibility.

# Introduction

R is widely used by non-programmers [@wickham2019], and this article aims to
introduce benchmarks in a non-technical yet formal manner for social scientists.
Our goal is to provide a fair comparison between Eigen and Armadillo, being both
highly efficient linear algebra libraries written in C++. We do it by using
[`cpp11armadillo`](https://pacha.dev/cpp11armadillo) and
[`cpp11eigen`](https://pacha.dev/cpp11eigen).

[Armadillo](https://arma.sourceforge.net/) is a C++ library designed for
linear algebra, emphasizing a balance between performance and ease of use.
C++ is highly efficient for computationally intensive tasks but lacks built-in
data structures and functions for linear algebra operations. Armadillo fills
this gap by providing an intuitive syntax similar to MATLAB [@sanderson2016].

[Eigen](https://eigen.tuxfamily.org/index.php?title=Main_Page) emphasizes
flexibility and speed, while [Armadillo](http://arma.sourceforge.net/) focuses
on a balance between speed and easy of use.

[`RcppArmadillo`](https://cran.r-project.org/package=RcppArmadillo), introduced
in 2010, integrates R and Armadillo [@sanderson2016; @eddelbuettel2014].
[`RcppEigen`](https://cran.r-project.org/package=RcppEigen), introduced in 2011,
integrates Eigen with R through the `Rcpp` package introduced in 2008, enabling
the use of C++ for performance-critical parts of R code. At the time of writing
this document, 732 CRAN packages depend on `RcppArmadillo` and 238 on
`RcppEigen` [@lee2024], and therefore these are highly successful packages
considering that the median number of reverse dependencies for CRAN packages is
five and the distribution of dependencies situates these packages as top one
percent.

`cpp11armadillo` and `cpp11eigen` are independent project that aim to simplify
the integration of R and C++ by using `cpp11`, an R package introduced in 2020
that eases calling C++ functions from R, it is currently used as a dependency
by 75 CRAN packages, and it is in the top one percent of CRAN packages
[@cran2024].

A distinctive characteristic of `cpp11armadillo` and `cpp11eigen` is the
vendoring capability, meaning that it allows to copy its code into a project,
making it a one-time dependency with a fixed and stable code until it is
manually updated. This feature is useful in restricted environments such as
servers and clusters where sometimes there are restrictions to software
installation or the internet connections are limited for security reasons
[@wickham2019; @cpp11].

`cpp11armadillo` and `cpp11eigen` are useful in cases where vectorization (e.g.,
applying an operation to a vector or matrix as a whole instead of looping over
each element) is not possible or challenging. A detailed discussion and examples
about why and when (and when not) rewriting R code in C++ is useful can be found
in @burns2011r. We followed four design principles when developing these two
packages as in: column oriented, package oriented, header-only,
and vendoring capable. The details of the `cpp11armadillo` implementation, which
is similar to `cpp11eigen`, can be found in @vargas2024b.

# Syntax

One possibility is to start by creating minimal R packages with the provided
templates. These templates provide a general case for a package that includes
the necessary files to create a package that uses Armadillo or Eigen, including
a generic `Makevars` file that can be adapted to link to specific numerical
libraries such as Intel MKL or OpenBLAS.

```r
remotes::install_github("pachadotdev/cpp11armadillo")
remotes::install_github("pachadotdev/cpp11eigen")

cpp11eigen::create_package("armadillobenchmark")
cpp11eigen::create_package("eigenbenchmark")
```

Comparing numerical libraries requires to write equivalent codes. For instance,
in R we use `apply()` while its C++ equivalent is a `for` loop, and this allows
a fair comparison between the two libraries. However, R has heavily optimized
functions that also verify the input data, such as `lm()` and `glm()`, which do
not have a direct equivalent in Armadillo or Eigen, and for a
fair comparison the options are to write a simplified function for the linear
model in R or to write a more complex function in C++.

The ATT benchmark, is a set of functions that can be rewritten using Armadillo
and Eigen with relative ease, and test has the advantage of being well-known and
widely used in the R community.

The first test in the ATT benchmark is the creation, transposition and
deformation of an $N \times N$ matrix ($2,500 \times 2,500$ in the original
test). The R and Armadillo codes for this operation are:

```r
# R

matrix_calculation_01_r <- function(n) {
  a <- matrix(rnorm(n * n) / 10, ncol = n, nrow = n)
  b <- t(a)
  dim(b) <- c(n / 2, n * 2)
  a <- t(b)
  return(0L)
}
```

```cpp
// C++

#include <cpp11.hpp>
#include <cpp11armadillo.hpp>

using namespace arma;
using namespace cpp11;

[[cpp11::register]] int matrix_calculation_01_arma_(const int& n) {
  mat a = randn<mat>(n,n) / 10;
  mat b = a.t();
  b.reshape(n/2, n*2);
  a = b.t();
  return 0;
}
```

The Eigen code requires to create a function to draw random numbers from a
normal distribution because it only provides a built-in function for the uniform
distribution:

```cpp
#include <cpp11.hpp>
#include <cpp11eigen.hpp>
#include <random>

using namespace Eigen;
using namespace cpp11;

std::mt19937& random_normal() {
  static std::random_device rd;
  static std::mt19937 gen(rd());
  return gen;
}

[[cpp11::register]] int matrix_calculation_01_eigen_(const int& n) {
  std::normal_distribution<double> d(0, 1);
  
  MatrixXd a = MatrixXd::NullaryExpr(n, n, [&]() {
    return d(random_normal());
  }) / 10;

  // for the uniform distribution this is just
  // MatrixXd a = MatrixXd::Random(n, n) / 10;

  MatrixXd b = a.transpose();
  b.resize(n / 2, n * 2);
  return 0;
}
```

# Benchmarks without data transfer

The functions in the previous section to do not move data between R and C++,
this is intentional to focus on the performance of the linear algebra libraries
and not adding overhead from data transfer in the benchmarks. Each function
creates a matrix and conducts equivalent operations on it. The returned value is
zero in R and C++ in case that the functions run without errors.

We decided to run the benchmarks on a local machine and on a cluster to provide
a comparison between the two environments and test how the benchmarks change
when the input data is increased.

## Local benchmarks

The local benchmarks were conducted on a ThinkPad X1 Carbon Gen 9 with the
following specifications:

- Processor: Intel Core i7-1185G7 with eight cores
- Memory: 16 GB LPDDR4Xx-4266
- Operating System: Pop!_OS 22.04 based on Ubuntu 22.04
- R Version: 4.4.1
- BLAS Library: OpenBLAS 0.3.20

The median times for the adapted and comparable implementations of the ATT
benchmarks are as follows:

```{r results, echo=FALSE, warning=FALSE, message=FALSE}
library(knitr)

d <- readRDS("tables-laptop-att-small.rds")

d1 <- d$d1
d2 <- d$d2
d3 <- d$d3

d1 <- d1[, c(1, 2, 4)]
d2 <- d2[, c(1, 2, 4)]
d3 <- d3[, c(1, 2, 4)]

kable(
  d1,
  caption = "Matrix calculation",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)

kable(
  d2,
  caption = "Matrix functions",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)

kable(
  d3,
  caption = "Programmation",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)
```

The results reveal that Armadillo leads in most of the benchmarks, but Eigen is
particularly faster in some tests such as the Fast Fourier Transform. R is the
second or third in all benchmarks, but it is important to note that R comes
with an additional advantage in terms of simplified syntax and the ability to
run the code without compiling it.

These tests are not exhaustive, and we must be cautious when interpreting the
results. The ATT benchmark is a good starting point, but it does not cover
mundane tasks such as data manipulation, and it is important to consider the
tradeoff between computational efficiency and ease of use.

## Cluster benchmarks

The cluster benchmarks were conducted on one cluster node of the
[Niagara supercomputer](https://docs.alliancecan.ca/wiki/Niagara) maintained by
the Digital Research Alliance of Canada, which has the following specifications:

- Processor: 2 sockets with 20 Intel Skylake cores (2.4GHz, AVX512), for a
  total of 40 cores per node
- Memory: 202 GB
- Operating System: CentOS 7
- R Version: 4.2.2
- BLAS Library: Intel MKL 2019.4.243

The median times for the adapted and comparable implementations of the ATT
benchmarks are as follows:

```{r results2, echo=FALSE, warning=FALSE, message=FALSE}
d <- readRDS("tables-niagara-att-small.rds")

d1 <- d$d1
d2 <- d$d2
d3 <- d$d3

d1$operation <- paste0(d1$operation, " - ", d1$software)
d2$operation <- paste0(d2$operation, " - ", d2$software)
d3$operation <- paste0(d3$operation, " - ", d3$software)

d1 <- d1[, c(1, 3, 5)]
d2 <- d2[, c(1, 3, 5)]
d3 <- d3[, c(1, 3, 5)]

kable(
  d1,
  caption = "Matrix calculation",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)

kable(
  d2,
  caption = "Matrix functions",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)

kable(
  d3,
  caption = "Programmation",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)
```

Repeating the same after multiplicating the number of rows and columns by five
leads to the following results:

```{r results3, echo=FALSE, warning=FALSE, message=FALSE}
d <- readRDS("tables-niagara-att-large.rds")

d1 <- d$d1
d2 <- d$d2
d3 <- d$d3

d1$operation <- paste0(d1$operation, " - ", d1$software)
d2$operation <- paste0(d2$operation, " - ", d2$software)
d3$operation <- paste0(d3$operation, " - ", d3$software)

d1 <- d1[, c(1, 3, 5)]
d2 <- d2[, c(1, 3, 5)]
d3 <- d3[, c(1, 3, 5)]

kable(
  d1,
  caption = "Matrix calculation",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)

kable(
  d2,
  caption = "Matrix functions",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)

kable(
  d3,
  caption = "Programmation",
  # col.names = c("Operation", "Median time (s)", "Time (% to best time)", "Rank"),
  col.names = c("Operation", "Median time (s)", "Rank"),
  # align = c("l", "r", "r", "r")
  align = c("l", "r", "r")
)
```

The results are consistent with the local benchmarks, and Armadillo leads in
most of the tests. The benchmarks are also consistent with the time complexity
of the algorithms, meaning that doubling the size of the matrix does not double
the time to run the function unless the function has a time complexity of
$O(n)$.

# Similarities between C++ libraries and R packages

The syntax and speed differences when using Armadillo or Eigen in C++ posit a
similar case to the tradeoff between using `dplyr` and `data.table`
[@wickham2019;@barrett2024], where `dplyr` is easier to use but `data.table` is
faster. `dplyr` was not designed to be fast but `data.table` was not designed to
be easy to use. For instance, the code to obtain the grouped means by number of
cylinders in the `mtcars` dataset is:

```r
# dplyr
mtcars %>%
  group_by(cyl) %>%
  summarise_all(mean)

# data.table
as.data.table(mtcars)[, lapply(.SD, mean), by = cyl]
```

The local benchmark for the grouped means reveals that `dplyr` has a median time
of 2.7 ms and `data.table` has a median time of 600 $\mu$s, meaning that
`dplyr` is four times slower than `data.table` at this task. The syntax of
`dplyr` is easier to understand for non-programmers, but `data.table` can be
equally expressive for users who are familiar with its syntax.

The tests for Armadillo and Eigen reveal that, for repeated and computationally
intensive tasks, rewriting R code in C++ can lead to significant performance
improvements, but it comes at the cost of learning a new syntax.

As with `dplyr` and `data.table`, the choice between Armadillo and Eigen
depends on the user's needs and preferences. For instance, Armadillo or Eigen
can be ideal to work with a $1,000,000 \times 1,000,000$ matrix but R can be
more suitable for a $1,000 \times 1,000$ matrix, and something similar applies
to `dplyr` that is suitable for a 2-4 GB CSV files or SQL data but `data.table`
is more suitable for 100 GB CSV datasets.

# Cases where Armadillo and Eigen stand out

Using Armadillo or Eigen can be particularly useful for functions that involve
nested loops and recursion. If we are going to repeatedly use a function that
requires nested loops, it may be worth rewriting it in C++ using Armadillo or
Eigen instead of using base R. In such cases, the time incurred in learning the
syntax and obtaining the correct function is an investment that pays off in
long run time savings.

For instance, @vargassepulveda2020 uses base R and the Matrix package to
calculate the Balassa index and provides international trade data for 226
countries and 785 exported commodities. A matrix of $226\times 785$ does not
pose a problem for base R, nor it counts as big data, but it shows large speed
gains when using Armadillo or Eigen.

Let $X \in \mathbb{R}^{C\times P}$ be a matrix with entries $x_{c,p}$ that
represents the exports of country $c$ in product $p$, from this matrix the
Balassa indices matrix is calculated as:

\begin{equation}
\label{eq:balassa1}
B = ([X \oslash (X \vec{1}_{P\times 1})]^t \oslash  [X^t \vec{1}_{C\times 1} \oslash (\vec{1}_{C\times 1}^t X \vec{1}_{P\times 1})])^t,
\end{equation}

where $\oslash$ denotes element-wise division and $t$ denotes transposition.

This is the same as the Balassa index for country $c$ and product $p$:
\begin{equation}
\label{eq:balassa2}
B_{cp} = \frac{x_{cp}}{\sum_c x_{cp}} / \frac{\sum_p x_{cp}}{\sum_{c}\sum_{p} x_{cp}}.
\end{equation}

$B$ is often used to produce a zeroes and ones matrix $S$ defined as:

\begin{equation}
\label{eq:balassa3}
s_{c,p} = \begin{cases}1 & \text{ if } b_{cp} > 1\cr 0 & \text{ otherwise} \end{cases},
\end{equation}

where a value of one indicates that country $c$ has a revealed comparative
advantage in product $p$ and zero otherwise.

\eqref{eq:balassa3} can be implemented in base R as:

```r
balassa_r <- function(X) {
  B <- t(t(X / rowSums(X)) / (colSums(X) / sum(X)))
  B[B < 1] <- 0
  B[B >= 1] <- 1
  B
}
```

The C++ code using `cpp11armadillo` is:

```cpp
#include <cpp11.hpp>
#include <cpp11armadillo.hpp>

using namespace cpp11;
using namespace arma;

[[cpp11::register]] doubles_matrix<> balassa_arma_(
  const doubles_matrix<>& x) {
  mat X = as_Mat(x);

  mat B = X.each_col() / sum(X, 1);
  B = B.each_row() / (sum(X, 0) / accu(X));
  B.elem(find(B < 1)).zeros();
  B.elem(find(B >= 1)).ones();

  return as_doubles_matrix(B);
}
```

The C++ code using `cpp11eigen` is:

```cpp
#include <cpp11.hpp>
#include <cpp11eigen.hpp>

using namespace cpp11;
using namespace Eigen;

[[cpp11::register]] doubles_matrix<> balassa_eigen_(
  const doubles_matrix<>& x) {
  MatrixXd X = as_Matrix(x);

  MatrixXd B = X.array().rowwise() / X.rowwise().sum().array();
  B = B.array().colwise() / (X.colwise().sum().array() / X.sum());
  B = (B.array() < 1).select(0, B);
  B = (B.array() >= 1).select(1, B);

  return as_doubles_matrix(B);
}
```

If we use UN COMTRADE data for the year 2020 for 234 countries and 5,386
countries [@unitednations2023], we can observe that Armadillo and Eigen are
around two times faster than base R at obtaining the Balassa matrix, and this
includes the time to move the data between R and C++:

```{r balassa, echo=FALSE, warning=FALSE, message=FALSE}
d <- data.frame(
  `Operation` = paste("Balassa indices", c("Eigen", "Armadillo", "R")),
  `Median time (s)` = c(0.013, 0.014, 0.026),
  `Rank` = c(1, 2, 3)
)

kable(
  d,
  caption = "Balassa indices",
  col.names = c("Operation", "Median time (s)", "Rank"),
  align = c("l", "r", "r")
)
```

The rest of the methods in @vargassepulveda2020 involve recursion and
eigenvalues computation, and these tasks were already covered in the ATT
benchmark, meaning that the same speed gains can be expected as in the Balassa
matrix.

# Benchmarks with data transfer

@psarras2022 provides different benchmarks for the Linear Algebra Mapping
Problem. We have adapted their benchmarks to solve linear systems in order to
extrapolate their findings to a larger input data.

We repeated the experiment consisting in solving a linear system of equations
$AX = B$ with $A \in \mathbb{R}^{n \times n}$ and
$B \in \mathbb{R}^{n \times m}$ for $n = 30,000$ and $m = 1,000$. Because
only `cpp11armadillo` has available methods to pass sparse matrices between
R and C++, we created dense matrices to also include `cpp11eigen` in the
comparison, and this also adds additional stress to the tests.

A dense matrix with double precision entries
$A \in \mathbb{R}^{30,000 \times 30,000}$ uses 6.7 GB of RAM and can be
created and operated in the Niagara cluster without problems. The benchmark
repeats the same task in two different ways, in a naive way by directly
computing $A^{-1}B$ and in a smart way by using `solve(A,B)`. The solution
always exists because the data is created by first defining random matrices $A$
and $X$ and then computing $B = AX$, the benchmarks use $A$ and $B$ as inputs to
solve for $X$. For the cases where $A^{-1}$ is not directly obtained, R and
Armadillo use the LU decomposition by inspecting the matrix structure while in
Eigen this has to be specified, and this is the correct approach provided that
$A$ was created with the `rnorm()` function in R without guarantee of symmetry
nor it results in an overdetermined system.

The benchmark results are as follows:

```{r results4, echo=FALSE, warning=FALSE, message=FALSE}
d <- readRDS("tables-niagara-psarras.rds")
d <- d[, c(1, 4, 5)]
d[, 2] <- round(d[, 2], 3)

kable(
  d,
  caption = "Solving linear systems",
  col.names = c("Operation", "Median time (s)", "Rank"),
  align = c("l", "r", "r")
)
```

Armadillo leads in performance for the naive solution. This means that, even
after considering the overhead of data transfer, Armadillo excels at
computationally intensive tasks that involve repeated operations as it is the
case of repeating row and column multiplication to obtain $X$, and this
benchmark does not cover additional data structures in C++ that do not exist in
R and that provide additional flexibility.

R leads in performance for the smart solution not because of the data transfer
overhead, but because R internally uses LAPACK and BLAS libraries that are
highly optimized for linear algebra operations. In the particular case of the
Niagara cluster, R was compiled against the Intel MKL library, which is highly
optimized for Intel processors and benefits from the specific processor
instructions set. Armadillo and Eigen in this case also use the Intel MKL
library, and for a benchmark with a smaller size input data (e.g.
$100\times 100$)the overhead of data transfer and using 40 cores would be higher
than the speed gains.

# Considerations

Being fair, R was not designed to be fast, and it is not a low-level language
like C++. R is a high-level language that some users consider easy to learn and
use, and it is particularly useful for data manipulation and visualization. R
has a large number of packages that can be used to conduct a wide range of
statistical analyses, and it is particularly useful for non-programmers.

Armadillo and Eigen are not designed to be easy to use, and they involve a
learning curve to use them effectively. These libraries are particularly useful
for computationally intensive tasks that involve nested loops and recursion.
These languages have speed advantages over R for two main reasons, that the
time it takes for each step in a loop is shorter in C++ than in R, and that
these libraries provide efficient data structures for vectors and matrices
besides providing internal methods that combine operations to increase speed
and reduce memory usage.

The choice between R and C++ depends on the user's needs and preferences. In a
way, comparing R and C++ is like comparing a Vespa and a Ducati motorcycle, both
are motorcycles but they are designed for different purposes and excel in
different areas. For instance, a Vespa is ideal for city commuting and a Ducati
is ideal for racing, and the same applies to R and C++.

Using C++ for tasks such as data manipulation and visualization is like using a
Ford F-150 to go to the convenience store, it is feasible but it is not the most
efficient way to do it and the additional fuel consumption compared to a lighter
vehicle ressembles the extra time required to compile and corrrect the code. In
the same way, using R for computationally intensive tasks is like using a Mini
Cooper to load bricks and construction materials, it is feasible but you cannot
expect the same experience (e.g., speed and comfort) as using a Ford F-150 for
the same task.

Writing proper C++ code requires a good understanding of the syntax and reading
the respective documentation that each library provides. For instance, without
reading the Armadillo documentation, it is very tempting to transpose a matrix
in the following way:

```cpp
mat bad_transposition_(const int& n) {
  mat a = randn<mat>(n, n) / 10;
  
  mat b(a.n_cols, a.n_rows);

  for (int i = 0; i < a.n_rows; i++) {
    for (int j = 0; j < a.n_cols; j++) {
      b(i, j) = a(j, i);
    }
  }

  return b;
}
```

Or, even worse, trying to make it faster by using OMP, which would be faster
but not efficient in terms of syntax and available alternatives:

```cpp
mat less_bad_transposition_(const int& n) {
  mat a = randn<mat>(n, n) / 10;
  
  mat b(a.n_cols, a.n_rows);

  #ifdef _OPENMP
  #pragma omp parallel for collapse(2) schedule(static)
  #endif
  for (int i = 0; i < a.n_rows; i++) {
    for (int j = 0; j < a.n_cols; j++) {
      b(i, j) = a(j, i);
    }
  }

  return b;
}
```

The correct way to transpose a matrix in Armadillo, such that its internals
apply low-level optimizations, is to use the `t()` function, and it also saves
time and typing:

```cpp
mat good_transposition_(const int& n) {
  mat a = randn<mat>(n, n) / 10;
  return a.t();
}
```

# Conclusion

Armadillo and Eigen can be highly expressive, these are flexible libraries once
the user has learned the syntax, and these languages have data structures that 
do not exist in R that help to write efficient code. Eigen and `cpp11eigen` do
not simplify the process of writing C++ code for R users but excels at
computationally demanding applications. Armadillo and `cpp11armadillo`, on the
other hand, provides a balance between speed and ease of use, and it is a good
choice for users who need to write C++ code that is easier to modify and
maintain.

# Acknowledgements

I appreciate that Paolo Bientinesi from Umea University read a previous version
of this document on arXiv and referred me to @psarras2022.

# References
